import { MDocument } from "@mastra/rag"
import * as fs from 'fs'
import { glob } from 'fs/promises'
import * as path from 'path'
import { embedMany } from "ai";
import { INDEX_NAME, VECTOR_CONFIG, EMBEDDING_MODEL, createVectorStore } from './config.js'

export async function createDb(patterns?: string[]) {
  const filePatterns = patterns && patterns.length > 0 ? patterns : []

  if (filePatterns.length === 0) {
    throw new Error('No patterns provided')
  }
  
  console.log('ðŸ” Finding markdown files...')
  const allFiles: string[] = []
  
  for (const pattern of filePatterns) {
    try {
      const matchedFiles: string[] = []
      for await (const file of glob(pattern, { cwd: process.cwd() })) {
        matchedFiles.push(path.resolve(file))
      }
      allFiles.push(...matchedFiles)
    } catch (error) {
      console.warn(`âš ï¸ Warning: Could not process pattern "${pattern}":`, error)
    }
  }

  if (allFiles.length === 0) {
    throw new Error('No markdown files found matching the provided patterns')
  }

  console.log(`ðŸ“– Reading ${allFiles.length} markdown files...`)
  const allChunks: any[] = []
  
  for (const filePath of allFiles) {
    try {
      const markdownContent = fs.readFileSync(filePath, 'utf-8')
      console.log(`  âœ… Processing: ${path.basename(filePath)}`)
      
      const docFromMarkdown = MDocument.fromMarkdown(markdownContent);
      const chunks = await docFromMarkdown.chunk()
      
      const chunksWithMetadata = chunks.map(chunk => ({
        ...chunk,
        filePath: filePath
      }))
      
      allChunks.push(...chunksWithMetadata)
    } catch (error) {
      console.warn(`âš ï¸ Warning: Could not process file "${filePath}":`, error)
    }
  }

  console.log(`âœ‚ï¸ Total chunks created: ${allChunks.length}`)

  console.log('ðŸ—„ï¸ Creating vector store...')
  const vectorStore = createVectorStore()

  console.log('ðŸ“Š Creating index...')
  await vectorStore.createIndex({
    indexName: INDEX_NAME,
    dimension: VECTOR_CONFIG.dimension,
    metric: VECTOR_CONFIG.metric,
  })

  console.log(`ðŸ”¢ Generating embeddings for ${allChunks.length} chunks...`)
  const { embeddings } = await embedMany({
    model: EMBEDDING_MODEL,
    values: allChunks.map(chunk => chunk.text),
  })

  console.log('ðŸ’¾ Storing embeddings...')
  await vectorStore.upsert({
    indexName: INDEX_NAME,
    vectors: embeddings,
    metadata: allChunks.map(chunk => ({
      text: chunk.text,
      filePath: chunk.filePath,
    })),
  })

  console.log('âœ… Database created successfully!')
  return { vectorStore, embeddings, chunks: allChunks }
}
